# Enhanced LLM Collaboration App

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Demo](#demo)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## Overview

The **Enhanced LLM Collaboration App** is a Python-based application designed to facilitate seamless collaboration between multiple Large Language Models (LLMs) such as OpenAI, Anthropic, Groq, and Ollama. Built with a modern and intuitive graphical user interface (GUI) using PyQt5, this application allows users to interact with different models, visualize response times, and manage collaboration settings efficiently.

## Features

- **Multi-Provider Support**: Interact with models from OpenAI, Anthropic, Groq, and Ollama.
- **Dynamic Model Selection**: Easily select and switch between available models.
- **Collaboration Mode**: Enable collaborative interactions between two selected models.
- **Real-Time Visualization**: Monitor response times and performance metrics through interactive charts.
- **Customizable Settings**: Configure API keys, collaboration rounds, token limits, temperature settings, and model roles.
- **Syntax Highlighting**: Enhanced readability of code snippets within the chat.
- **Theming**: Modern dark theme with customizable UI elements.
- **Responsive Design**: Adjustable layouts and scalable components for various screen sizes.
